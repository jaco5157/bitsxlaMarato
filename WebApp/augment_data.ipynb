{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### AUGMENT DATASET "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "folder_path = os.getcwd()\n",
    "input_path = folder_path + \"\\dataset\"\n",
    "\n",
    "# Define the PyTorch transform with random augmentations\n",
    "augmenter = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    #transforms.RandomResizedCrop((image.size[1], image.size[0]), scale=(0.9, 1.1)),\n",
    "    #transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5),\n",
    "    \n",
    "    transforms.RandomRotation(20, fill=255),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), fill=255),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomPerspective(distortion_scale=0.2, fill=255),\n",
    "    transforms.Grayscale(num_output_channels=1),  # Convert the image to grayscale\n",
    "    transforms.ToTensor(),  # Convert the PIL image to a PyTorch tensor\n",
    "])\n",
    "\n",
    "grey_scale = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),  # Convert the image to grayscale\n",
    "    transforms.ToTensor(),  # Convert the PIL image to a PyTorch tensor\n",
    "])\n",
    "\n",
    "# Iterate over all images in the folder\n",
    "for filename in os.listdir(input_path):\n",
    "    if filename.endswith(('.png', '.jpg', '.jpeg')):\n",
    "        image_path = os.path.join(input_path, filename)\n",
    "        \n",
    "        # Load the image\n",
    "        image = Image.open(image_path)\n",
    "\n",
    "        # Generate 5 different augmented images\n",
    "        for i in range(5):\n",
    "            # Apply the random augmentations\n",
    "            augmented_tensor = augmenter(image)\n",
    "            \n",
    "            # Convert the augmented tensor back to PIL format\n",
    "            augmented_image = transforms.ToPILImage()(augmented_tensor)\n",
    "\n",
    "            # Save the augmented image - adjust the output folder as needed\n",
    "            output_path = os.path.join( input_path, 'augmented', f'{i}{filename}.png')\n",
    "            augmented_image.save(output_path)\n",
    "\n",
    "        grey_tensor = grey_scale(image)\n",
    "        grey_image = transforms.ToPILImage()(grey_tensor)\n",
    "        # Save the augmented image - adjust the output folder as needed\n",
    "        output_path = os.path.join( input_path, 'augmented', filename)\n",
    "        grey_image.save(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD DATA AND GENERATE AUGMENTE DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea: use VGG16, a pre-trained network, since our dataset is both artificial and small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n"
     ]
    }
   ],
   "source": [
    "data_folder = os.path.join(input_path, 'augmented') # The folder containing the augmented and original images\n",
    "model_save_path = os.path.join(folder_path, \"model\"+\".pth\")\n",
    "\n",
    "#folder_path = os.getcwd()\n",
    "#input_path = folder_path + \"\\dataset\"\n",
    "\n",
    "# Define transformations for the training data\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    #transforms.Grayscale(num_output_channels=1)(image),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Create a custom dataset\n",
    "class MenstrualDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, folder_path, transform=None):\n",
    "        self.folder_path = folder_path\n",
    "        self.transform = transform\n",
    "        self.image_list = [f for f in os.listdir(folder_path) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_name = self.image_list[idx]\n",
    "        image_path = os.path.join(self.folder_path, image_name)\n",
    "        image = Image.open(image_path).convert(\"RGB\")  # Convert to RGB\n",
    "\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Extract the label from the image name (assuming the label is the number after '_')\n",
    "        label = int(image_name.split('_')[-1].split('.')[0])\n",
    "        return image, label\n",
    "\n",
    "# Create a custom dataset instance\n",
    "full_dataset = MenstrualDataset(data_folder, transform)\n",
    "\n",
    "print(f\"The dataset has {len(full_dataset)} images\")\n",
    "\n",
    "# Define the number of folds\n",
    "num_folds = 5\n",
    "\n",
    "# Use StratifiedKFold to ensure class distribution balance in each fold\n",
    "skf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Training loop with cross-validation\n",
    "for fold, (train_indices, val_indices) in enumerate(skf.split(full_dataset, [label for _, label in full_dataset])):\n",
    "    print(f\"Fold {fold + 1}/{num_folds}\")\n",
    "\n",
    "    # Create DataLoader instances for training and validation\n",
    "    train_dataset = Subset(full_dataset, train_indices)\n",
    "    val_dataset = Subset(full_dataset, val_indices)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=0)\n",
    "\n",
    "    # Load the pre-trained VGG-16 model\n",
    "    model = models.vgg16(pretrained=True)\n",
    "    num_classes = 3  # Change this according to your dataset\n",
    "    model.classifier[6] = nn.Linear(4096, num_classes)\n",
    "\n",
    "    # Set the device to GPU if available\n",
    "    device = torch.device(\"cpu\") #(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "\n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    # Training loop\n",
    "    num_epochs = 15 \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "    # Save the trained model for each fold\n",
    "    model_k = f'model_fold_{fold + 1}.pth'\n",
    "    model_k_path = os.path.join(folder_path, model_k)\n",
    "\n",
    "    torch.save(model.state_dict(), model_k_path)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "    # Compute and print accuracy for each fold\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    print(f\"Validation Accuracy (Fold {fold + 1}): {accuracy}\")\n",
    "\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
